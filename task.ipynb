{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "=> Epoch: 0 Average loss: 0.00074621\n",
      "=> Test set loss: 0.00050495\n",
      "=> Epoch: 1 Average loss: 0.00049294\n",
      "=> Test set loss: 0.00047602\n",
      "=> Epoch: 2 Average loss: 0.00048463\n",
      "=> Test set loss: 0.00047472\n",
      "=> Epoch: 3 Average loss: 0.00048383\n",
      "=> Test set loss: 0.00047429\n",
      "=> Epoch: 4 Average loss: 0.00048335\n",
      "=> Test set loss: 0.00047339\n",
      "=> Epoch: 5 Average loss: 0.00048291\n",
      "=> Test set loss: 0.00047343\n",
      "=> Epoch: 6 Average loss: 0.00048233\n",
      "=> Test set loss: 0.00047283\n",
      "=> Epoch: 7 Average loss: 0.00048214\n",
      "=> Test set loss: 0.00047280\n",
      "=> Epoch: 8 Average loss: 0.00048186\n",
      "=> Test set loss: 0.00047245\n",
      "=> Epoch: 9 Average loss: 0.00048180\n",
      "=> Test set loss: 0.00047240\n",
      "Success!ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, inp_size, hid_size, lmbd = 1):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.lmbd = lmbd;\n",
    "        self.encodeOp = torch.nn.Linear(inp_size, hid_size);\n",
    "        self.decodeOp = torch.nn.Linear(hid_size, inp_size);\n",
    "        \n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encodeOp(x);\n",
    "\n",
    "    def decode(self, h):\n",
    "        return self.decodeOp(h);\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.decode(self.encode(x))\n",
    "\n",
    "\n",
    "    def loss_function(self, recon_x, x):        \n",
    "        return self.loss_function2(recon_x, x)\n",
    "        loss_f = torch.nn.MSELoss()\n",
    "        mse = torch.nn.functional.mse_loss(recon_x, x);\n",
    "        rglzr = 0;\n",
    "        for p in self.parameters():\n",
    "            rglzr += p.data.norm(p = 1);\n",
    "            \n",
    "        return mse + self.lmbd * rglzr;\n",
    "    \n",
    "    def loss_function2(self, recon_x, x):\n",
    "        return recon_x.add(1).sub(x.add(1)).var();\n",
    "        \n",
    "\n",
    "\n",
    "def train(model, optimizer, train_loader, test_loader):\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        train_loss, test_loss = 0, 0\n",
    "        for data, _ in train_loader:\n",
    "            #print(data.view(-1)[0], data.view(-1)[1], data.view(-1)[2])\n",
    "            data = Variable(data).view(-1, 784)\n",
    "            x_rec = model(data)\n",
    "            loss = model.loss_function(x_rec, data)\n",
    " \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "  \n",
    "            optimizer.step()\n",
    "            train_loss += loss.data[0]\n",
    "        print('=> Epoch: %s Average loss: %.8f' % (epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "        model.eval()\n",
    "        for data, _ in test_loader:\n",
    "            data = Variable(data, volatile=True).view(-1, 784)\n",
    "            x_rec = model(data)\n",
    "            \n",
    "            test_loss += model.loss_function(x_rec, data).data[0]\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('=> Test set loss: %.8f' % test_loss)\n",
    "\n",
    "        n = min(data.size(0), 8)\n",
    "        comparison = torch.cat([data.view(-1, 1, 28, 28)[:n], x_rec.view(-1, 1, 28, 28)[:n]])\n",
    "        save_image(comparison.data.cpu(), 'pics/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_work():\n",
    "    print('Start test')\n",
    "    get_loader = lambda train: torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=train, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=50, shuffle=True)\n",
    "    train_loader, test_loader = get_loader(True), get_loader(False)\n",
    "    \n",
    "    try:\n",
    "        model = AutoEncoder(inp_size=784, hid_size=20, lmbd = 0.5)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    except Exception:\n",
    "        assert False, 'Error during model creation'\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        model = train(model, optimizer, train_loader, test_loader)\n",
    "    except Exception:\n",
    "        assert False, 'Error during training'\n",
    "        return\n",
    "\n",
    "    test_x = Variable(torch.randn(1, 784))    \n",
    "    rec_x, hid_x = model(test_x), model.encode(test_x)\n",
    "    submodules = dict(model.named_children())\n",
    "    layers_with_params = np.unique(['.'.join(n.split('.')[:-1]) for n, _ in model.named_parameters()])\n",
    "    \n",
    "    assert (hid_x.dim() == 2) and (hid_x.size(1) == 20),  'Hidden representation size must be equal to 20'\n",
    "    assert (rec_x.dim() == 2) and (rec_x.size(1) == 784), 'Reconstruction size must be equal to 784'\n",
    "    assert len(layers_with_params) <= 6, 'The model must contain not more than 6 layers'\n",
    "    assert np.all(np.concatenate([list(p.shape) for p in model.parameters()]) <= 800), 'All hidden sizes must be less than 800'\n",
    "    assert np.all([isinstance(submodules[name], nn.Linear) for name in layers_with_params]), 'All layers with parameters must be nn.Linear'\n",
    "    print('Success!ðŸŽ‰')\n",
    "\n",
    "test_work()\n",
    "\n",
    "#model = AutoEncoder(inp_size=2, hid_size=2, lmbd = 3)\n",
    "#for p in model.parameters():\n",
    "#    print(p.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3531"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.6682  + 0.6063 + 0.6192  + 0.4594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1798876465813697\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.randn(3, 5)\n",
    "x2 = torch.randn(3, 5)\n",
    "\n",
    "#mse = torch.nn.functional.mse_loss(x1,x2)\n",
    "print(x1.sub(x2).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2\n",
       " 3\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([1,2]).add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
