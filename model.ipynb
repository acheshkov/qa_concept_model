{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from shared import (squadIteratorGraph, readDicFromFile, loadSparseM, \n",
    "                    initEdgeVectors, mkGraph, nearestNodes, processOneExample, \n",
    "                    readFrequencyFile,\n",
    "                    getDistanceMatrix,\n",
    "                    spanDistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(torch.nn.Module):\n",
    "    def __init__(self, F_size):\n",
    "\n",
    "        super(MyLayer, self).__init__()\n",
    "        #self.L = torch.nn.Parameter(torch.randn(F_size, F_size))\n",
    "        self.L = torch.nn.Linear(F_size, 1)\n",
    "        #self.p_q = torch.nn.Parameter(torch.randn(1))\n",
    "        #self.p_s = torch.nn.Parameter(torch.randn(1))\n",
    "\n",
    "        #self.adjencyMatrixQ = adjencyMatrixQ\n",
    "        #self.adjencyMatrixS = adjencyMatrixS\n",
    "\n",
    "    def forward(self, X):\n",
    "        #print(self.adjencyMatrixQ.size())\n",
    "        #print(\"X\", X)\n",
    "        I = Variable(torch.eye(self.adjencyMatrixQ.size()[0]))\n",
    "        #print(self.adjencyMatrixQ.squeeze_)\n",
    "        #print(self.adjencyMatrixQ.matmul(X))\n",
    "        #W_q = (self.adjencyMatrixQ + I) * self.p_q.expand_as(self.adjencyMatrixQ)\n",
    "        #W_s = (self.adjencyMatrixS + I) * self.p_s.expand_as(self.adjencyMatrixS)\n",
    "        #W = W_q + W_s\n",
    "        #return W.matmul(X).matmul(self.L).sigmoid()\n",
    "        return self.L((self.adjencyMatrixQ + I).matmul(X))\n",
    "        \n",
    "\n",
    "    def bindAdjencyMatrix(self, adjencyMatrixQ):\n",
    "        self.adjencyMatrixQ = adjencyMatrixQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "squadIteratorGraph() missing 1 required positional argument: 'freq_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-75a2b9bb55a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadDicFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'squad_vocab_100K'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadSparseM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matrix_100K_reduced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainIter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msquadIteratorGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train-v1.1.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: squadIteratorGraph() missing 1 required positional argument: 'freq_dict'"
     ]
    }
   ],
   "source": [
    "#------- train ------\n",
    "vocab = readDicFromFile('squad_vocab_100K')\n",
    "matrix = loadSparseM('matrix_100K_reduced')\n",
    "trainIter = squadIteratorGraph('train-v1.1.json', vocab, matrix)\n",
    "\n",
    "model = MyLayer(4)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, ((gr, idxs), answer) in enumerate(trainIter, 0):\n",
    "        if (i < 118): continue\n",
    "        #print(answer)\n",
    "        # get the inputs\n",
    "        q_idxs = [v[\"idx\"] for v in idxs if v[\"in_question\"]]\n",
    "        #print(q_idxs)\n",
    "        #print(len(idxs), gr.shape[0])\n",
    "        p_idxs = [v[\"idx\"] for v in idxs if not v[\"in_question\"]]\n",
    "        inputs = initEdgeVectors(gr, q_idxs)\n",
    "        #print(\"inputs\", inputs.astype(int).dtype)\n",
    "        inputs = torch.from_numpy(inputs).float()\n",
    "        #print(type(inputs))\n",
    "        labels = [1.0 if v[\"in_answer\"] else 0 for v in idxs]\n",
    "        labels = torch.FloatTensor(labels).view(-1, 1)\n",
    "        \n",
    "        adjency_for_q = gr.copy().astype(float)\n",
    "        #print(\"adjency_for_q\", adjency_for_q.dtype)\n",
    "        \n",
    "        adjency_for_q[p_idxs, :] = 0\n",
    "        adjency_for_q[:, p_idxs] = 0\n",
    "        #print(\"gr copy\", adjency_for_q)\n",
    "        #print(\"adjency_for_q squeezed\", [v for v in adjency_for_q.getA1() if v > 0])\n",
    "        #print(\"adjency_for_q - 1\", [v for v in adjency_for_q.getA1() if v > 0])\n",
    "        #print(type(adjency_for_q))\n",
    "        #print(\"adjency_for_q\", torch.from_numpy(np.asarray(adjency_for_q)))\n",
    "        #print(\"type adjency_for_q\", adjency_for_q.dtype, type(adjency_for_q[0,0]))\n",
    "        #print(type([v for v in adjency_for_q.getA1() if v > 0]))\n",
    "        #print(type([1,2,3]))\n",
    "        #t = torch.from_numpy(np.array([v for v in adjency_for_q.getA1() if v > 0]))\n",
    "        #t.type(torch.IntTensor)\n",
    "        #print('adjency_for_q type', torch.from_numpy(adjency_for_q.getA()).type())\n",
    "        adjency_for_q = Variable(torch.from_numpy(adjency_for_q.getA()).float(), requires_grad = False) \n",
    "        #print(\"adjency_for_q - 2\", adjency_for_q.data.numpy())\n",
    "        model.bindAdjencyMatrix(adjency_for_q)\n",
    "        #print(\"inputs type\", type(inputs))\n",
    "        #print(\"labels type\", type(labels))\n",
    "\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs, requires_grad = False), Variable(labels, requires_grad = False)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        #print(outputs)\n",
    "        #print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        #print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, loss.data[0]))\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = Variable(torch.FloatTensor([[0, 1, 0], [1, 0, 1], [0, 1, 0]]), requires_grad = False)\n",
    "m2 = Variable(torch.FloatTensor([[0, 0, 1], [0, 0, 0], [1, 0, 0]]), requires_grad = False)\n",
    "X = Variable(torch.randn(3, 4), requires_grad = False) \n",
    "model = MyLayer(4)\n",
    "model.bindAdjencyMatrix(m1)\n",
    "X1 = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = readDicFromFile('vocab500K')\n",
    "matrix = loadSparseM('matrix_500K_sc4_reduced')\n",
    "freq_dict = readFrequencyFile(\"freq_vocab500K\")\n",
    "trainIter = squadIteratorGraph('train-v1.1.json', vocab, matrix, freq_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    next(trainIter)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      "Q:  What is in front of the Notre Dame Main Building?\n",
      "A:  a copper statue of Christ\n"
     ]
    }
   ],
   "source": [
    "(gr, idxs), answer, question, paragraph = next(trainIter)\n",
    "print(\"P: \", paragraph)\n",
    "print(\"Q: \", question)\n",
    "print(\"A: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q idxs: [1, 4, 10, 13, 14, 15, 18, 68, 69, 70, 71]\n",
      "Q: [(1, 'notre'), (4, 'students'), (10, 'at'), (13, 'in'), (14, 'first'), (15, 'year'), (18, 'was'), (68, 'what'), (69, 'created'), (70, 'dame'), (71, 'assist')]\n",
      "A idxs: [14, 15, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "q_idxs = [v[\"idx\"] for v in idxs if v[\"in_question\"]]\n",
    "q_idxs_words = [(v[\"idx\"], v['word']) for v in idxs if v[\"in_question\"]]\n",
    "print(\"Q idxs:\", q_idxs)\n",
    "print(\"Q:\", q_idxs_words)\n",
    "a_idxs = [i for i, v in enumerate(idxs) if v[\"in_answer\"]]\n",
    "print(\"A idxs:\", a_idxs)\n",
    "all_idxs = [v[\"idx\"] for v in idxs]\n",
    "dic_idx_to_word = dict([(v[\"idx\"], v[\"word\"]) for v in idxs])\n",
    "#idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[13543, 56990],\n",
       "        [ 3451,  3071],\n",
       "        [  259,  3696],\n",
       "        [  423,  3816],\n",
       "        [ 4788,  2047],\n",
       "        [ 2280,   840],\n",
       "        [33713, 53376]], dtype=uint16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr[q_idxs, :][:, a_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(28, 'major', 17804.846153846152, '1036686'),\n",
       " (10, 'at', 17807.23076923077, '13209400'),\n",
       " (72, 'for', 18034.23076923077, '20217315'),\n",
       " (13, 'in', 18305.384615384617, '66492400'),\n",
       " (23, 'their', 18607.923076923078, '4503807'),\n",
       " (15, 'year', 18627.538461538461, '2845442'),\n",
       " (17, 'program', 18736.0, '655622'),\n",
       " (62, 'by', 18749.153846153848, '17444726'),\n",
       " (11, 'school', 18792.538461538461, '2950021'),\n",
       " (31, 'is', 18810.307692307691, '21279224'),\n",
       " (14, 'first', 19318.384615384617, '5591677'),\n",
       " (24, 'before', 19349.307692307691, '1636083'),\n",
       " (64, 'news', 19538.23076923077, '492610'),\n",
       " (71, 'with', 19673.384615384617, '16941836'),\n",
       " (18, 'was', 20221.384615384617, '26107810'),\n",
       " (44, 'which', 20303.461538461539, '6588422'),\n",
       " (29, 'each', 20304.461538461539, '1190204'),\n",
       " (41, 'give', 20421.384615384617, '268419'),\n",
       " (73, 'new', 20959.923076923078, '5269523'),\n",
       " (4, 'students', 21183.538461538461, '669686'),\n",
       " (0, 'all', 21333.538461538461, '3448959'),\n",
       " (35, 'from', 21717.153846153848, '12751477'),\n",
       " (6, 'part', 21817.923076923078, '1937199'),\n",
       " (58, 'has', 21848.384615384617, '5188499'),\n",
       " (70, 'help', 22179.538461538461, '406088'),\n",
       " (48, 'learning', 22292.384615384617, '176533'),\n",
       " (52, 'time', 22598.461538461539, '3247882'),\n",
       " (12, 'or', 22949.76923076923, '5729279'),\n",
       " (36, 'who', 23167.76923076923, '4231819'),\n",
       " (30, 'student', 23200.384615384617, '354205'),\n",
       " (46, 'also', 23229.76923076923, '6589426'),\n",
       " (38, 'them', 23271.846153846152, '1453906'),\n",
       " (25, 'they', 23293.076923076922, '3892539'),\n",
       " (61, 'previously', 23304.384615384617, '330868'),\n",
       " (66, 'report', 23327.384615384617, '359382'),\n",
       " (26, 'have', 23428.846153846152, '3689854'),\n",
       " (19, 'established', 23636.384615384617, '660312'),\n",
       " (5, 'are', 23657.153846153848, '6858639'),\n",
       " (50, 'center', 24996.307692307691, '985975'),\n",
       " (57, 'this', 25314.76923076923, '5894033'),\n",
       " (51, 'provides', 25839.538461538461, '228643'),\n",
       " (68, 'what', 26406.846153846152, '832577'),\n",
       " (32, 'given', 27532.153846153848, '636136'),\n",
       " (7, 'one', 28055.076923076922, '4956154'),\n",
       " (27, 'declared', 28452.153846153848, '162175'),\n",
       " (59, 'been', 29820.615384615383, '3282902'),\n",
       " (65, 'world', 30120.615384615383, '2689387'),\n",
       " (63, 'us', 30511.0, '986053'),\n",
       " (53, 'management', 31363.923076923078, '426665'),\n",
       " (43, 'any', 31657.538461538461, '988143'),\n",
       " (8, 'five', 33292.230769230766, '950895'),\n",
       " (55, 'subject', 34822.230769230766, '230370'),\n",
       " (60, 'recognized', 38063.538461538461, '160015'),\n",
       " (47, 'includes', 39687.692307692305, '422385'),\n",
       " (16, 'studies', 39763.769230769234, '441027'),\n",
       " (20, 'guide', 40624.615384615383, '164052'),\n",
       " (9, 'colleges', 43383.307692307695, '85024'),\n",
       " (33, 'academic', 43483.923076923078, '232642'),\n",
       " (74, 'dame', 45838.153846153844, '72258'),\n",
       " (1, 'notre', 49458.538461538461, '51628'),\n",
       " (67, 'outstanding', 50157.846153846156, '167634'),\n",
       " (3, 'undergraduate', 50173.923076923078, '52493'),\n",
       " (40, 'classes', 50574.153846153844, '151763'),\n",
       " (45, 'interested', 50938.538461538461, '83326'),\n",
       " (69, 'entity', 56289.923076923078, '41180'),\n",
       " (37, 'helps', 58921.538461538461, '59412'),\n",
       " (39, 'choose', 59349.461538461539, '70239'),\n",
       " (34, 'advisor', 60487.538461538461, '47995'),\n",
       " (49, 'resource', 60960.307692307695, '66287'),\n",
       " (42, 'exposure', 62789.384615384617, '58453'),\n",
       " (54, 'collaborative', 63720.692307692305, '28140'),\n",
       " (21, 'incoming', 64630.0, '17631'),\n",
       " (22, 'freshmen', 64917.692307692305, '7578'),\n",
       " (2, 'dames', 70989.153846153844, '4386'),\n",
       " (56, 'tutoring', 75700.692307692312, '4597')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = mkGraph(gr)\n",
    "nearest = nearestNodes(graph, q_idxs, all_idxs)\n",
    "[(idx, dic_idx_to_word[idx], dist, freq_dict[dic_idx_to_word[idx]]) for (idx, dist) in nearest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 37842.0)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearestNodes(graph, [13], [12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence #0 has distance 0.04923540531571137\n",
      "skip unknown word: 's\n",
      "sentence #1 has distance 0.0632554063281528\n",
      "sentence #2 has distance 0.04347914061466824\n",
      "sentence #3 has distance 0.008773189608067146\n",
      "sentence #4 has distance 0.0764841085694712\n",
      "sentence #5 has distance 0.04605734265171164\n",
      "sentence #6 has distance 0.04147372590427224\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6feb6b8f7c8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspanDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistanceMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm_word_idx_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'sentence #{idx} has distance {d}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#print(f\"foo is {bar}.\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/working/shared.py\u001b[0m in \u001b[0;36mspanDistance\u001b[0;34m(span, question, distanceMatrix, dm_word_idx_map)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mdss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "#question = 'undergraduate'\n",
    "# paragraph = \"All of Notre Dame's undergraduate students are a part of one of the five undergraduate colleges at the school or are in the First Year of Studies program.\"\n",
    "# #question = 'tissue'\n",
    "# #answer = ''\n",
    "# (gr, idxs), answer, question, paragraph = processOneExample(vocab, matrix, answer, question, paragraph, freq_dict)\n",
    "# print(\"P: \", paragraph)\n",
    "# print(\"Q: \", question)\n",
    "# print(\"A: \", answer)\n",
    "# q_idxs = [v[\"idx\"] for v in idxs if v[\"in_question\"]]\n",
    "# all_idxs = [v[\"idx\"] for v in idxs]\n",
    "# dic_idx_to_word = dict([(v[\"idx\"], v[\"word\"]) for v in idxs])\n",
    "# graph = mkGraph(gr)\n",
    "# nearest = nearestNodes(graph, q_idxs, all_idxs, avg=False)\n",
    "\n",
    "\n",
    "# new approach\n",
    "#span = '''At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.''' # list of words (paragraph substring)\n",
    "distanceMatrix, dm_word_idx_map = getDistanceMatrix(matrix, paragraph, question, vocab)\n",
    "\n",
    "for idx, sentence in enumerate(paragraph.split('.')):\n",
    "    d = spanDistance(sentence, question, distanceMatrix, dm_word_idx_map)\n",
    "    print(f'sentence #{idx} has distance {d}')\n",
    "    #print(f\"foo is {bar}.\")\n",
    "#[(idx, dic_idx_to_word[idx], dist, freq_dict[dic_idx_to_word[idx]]) for (idx, dist) in nearest]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<NNP>': 6,\n",
       " '<NUM>': 38,\n",
       " 'allegedly': 53,\n",
       " 'and': 16,\n",
       " 'appear': 54,\n",
       " 'appeared': 37,\n",
       " 'architecturally': 0,\n",
       " 'arms': 21,\n",
       " 'at': 34,\n",
       " 'atop': 5,\n",
       " 'basilica': 27,\n",
       " 'behind': 26,\n",
       " 'catholic': 3,\n",
       " 'character': 4,\n",
       " 'connects': 45,\n",
       " 'copper': 19,\n",
       " 'did': 52,\n",
       " 'direct': 42,\n",
       " 'dome': 8,\n",
       " 'drive': 41,\n",
       " 'end': 39,\n",
       " 'facing': 17,\n",
       " 'front': 15,\n",
       " 'gold': 7,\n",
       " 'golden': 10,\n",
       " 'grotto': 33,\n",
       " 'has': 2,\n",
       " 'immediately': 13,\n",
       " 'in': 14,\n",
       " 'is': 9,\n",
       " 'it': 18,\n",
       " 'legend': 23,\n",
       " 'line': 43,\n",
       " 'main': 40,\n",
       " 'marian': 28,\n",
       " 'modern': 49,\n",
       " 'next': 24,\n",
       " 'of': 12,\n",
       " 'place': 29,\n",
       " 'prayer': 30,\n",
       " 'reflection': 31,\n",
       " 'replica': 32,\n",
       " 'reputedly': 36,\n",
       " 'school': 1,\n",
       " 'simple': 48,\n",
       " 'statue': 11,\n",
       " 'statues': 47,\n",
       " 'stone': 50,\n",
       " 'that': 44,\n",
       " 'through': 46,\n",
       " 'to': 25,\n",
       " 'upraised': 22,\n",
       " 'where': 35,\n",
       " 'whom': 51,\n",
       " 'with': 20}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_word_idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Architecturally, the school has a Catholic character \n",
      "\n",
      "1  Atop the Main Building's gold dome is a golden statue of the Virgin Mary \n",
      "\n",
      "2  Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\" \n",
      "\n",
      "3  Next to the Main Building is the Basilica of the Sacred Heart \n",
      "\n",
      "4  Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection \n",
      "\n",
      "5  It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858 \n",
      "\n",
      "6  At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary \n",
      "\n",
      "7  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, s in enumerate(paragraph.split('.')):\n",
    "    print(f'{idx} {s} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is in front of the Notre Dame Main Building?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.        ,  0.15056995,  0.15819735, ...,  0.12762819,\n",
       "          0.09158271,  0.14835831],\n",
       "        [ 0.15056995,  0.        ,  0.03894468, ...,  0.05883895,\n",
       "          0.09925219,  0.05203693],\n",
       "        [ 0.15819735,  0.03894468,  0.        , ...,  0.05822956,\n",
       "          0.10525457,  0.05075235],\n",
       "        ..., \n",
       "        [ 0.12762819,  0.05883895,  0.05822956, ...,  0.        ,\n",
       "          0.06984629,  0.05392935],\n",
       "        [ 0.09158271,  0.09925219,  0.10525457, ...,  0.06984629,\n",
       "          0.        ,  0.09147715],\n",
       "        [ 0.14835831,  0.05203693,  0.05075235, ...,  0.05392935,\n",
       "          0.09147715,  0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distanceMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distanceMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
